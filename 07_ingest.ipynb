{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp ingest.ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\r\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\r\n",
    "\r\n",
    "import re\r\n",
    "import pymongo\r\n",
    "import json\r\n",
    "import sc2reader\r\n",
    "import errno\r\n",
    "import jsonschema\r\n",
    "import os\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "\r\n",
    "from typing import *\r\n",
    "from pathlib import Path\r\n",
    "from pprint import pprint\r\n",
    "from jsonschema import validate\r\n",
    "from dataclasses import dataclass, astuple, asdict, field\r\n",
    "\r\n",
    "from sc_training.ingest import *\r\n",
    "\r\n",
    "sc2reader.engine.register_plugin(CtrlGroupTracker())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \r\n",
    "\r\n",
    "test_data_path = (Path(Path.cwd()/'test_replays') \r\n",
    "                  if Path('test_replays').exists() \r\n",
    "                  else Path('../../test_replays'))\r\n",
    "\r\n",
    "test_batch_path = (test_data_path / \"TestProfilerBatch\")\r\n",
    "\r\n",
    "assert test_data_path.exists()\r\n",
    "assert test_data_path.is_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.7 - The main ingest module "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\r\n",
    "\r\n",
    "This section defines the ingest process' `inventory_replays` and `get_replay_indicators` functions following the design proposed in the Ingestion Sequence Diagram (see Section 1 - Data Ingestion and Clustering Process). It exports these functions into the ingest module of the ingest sub-package.\r\n",
    "\r\n",
    "### Exportable Members\r\n",
    "- `inventory_replays`\r\n",
    "- `get_replay_indicators`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inventoring and Storing `replays` collection\r\n",
    "\r\n",
    "To inventory the replays in a replay batch I can use the `get_replay_info` defined in the `summarise_rpl` module (see Section 1.1).\r\n",
    "\r\n",
    "In the following code, I load a batch of replays and I print the summary of the first two replays using the `get_replay_info` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path:                   c:\\Users\\david\\Documents\\phdcode\\sc_training\\test_replays\\TestProfilerBatch\\16-Bit LE (2).SC2Replay \n",
      "File name:                   16-Bit LE (2).SC2Replay \n",
      "Date (datetime.datetime):    2021-06-04 03:49:10 \n",
      "Duration (seconds):          707 \n",
      "Game type:                   1v1 \n",
      "Game release:                5.0.7.84643 \n",
      "Map:                         16-Bit LE \n",
      "Game category:               Private \n",
      "winner:                      1 \n",
      "players:                     [(1, 'HDEspino', 'Terran', 'Win'), (2, 'A.I. 1 (Harder)', 'Zerg', 'Loss')] \n",
      "\n",
      "<class 'sc_training.ingest.summarise_rpl.Replay_data'>\n",
      "File path:                   c:\\Users\\david\\Documents\\phdcode\\sc_training\\test_replays\\TestProfilerBatch\\16-Bit LE (3).SC2Replay \n",
      "File name:                   16-Bit LE (3).SC2Replay \n",
      "Date (datetime.datetime):    2021-06-08 02:04:37 \n",
      "Duration (seconds):          384 \n",
      "Game type:                   1v1 \n",
      "Game release:                5.0.7.84643 \n",
      "Map:                         16-Bit LE \n",
      "Game category:               Private \n",
      "winner:                      1 \n",
      "players:                     [(1, 'HDEspino', 'Protoss', 'Win'), (2, 'A.I. 1 (Easy)', 'Protoss', 'Loss')] \n",
      "\n",
      "<class 'sc_training.ingest.summarise_rpl.Replay_data'>\n"
     ]
    }
   ],
   "source": [
    "replay_batch = sc2reader.load_replays(str(test_batch_path))\r\n",
    "\r\n",
    "for i, rpl in enumerate(replay_batch):\r\n",
    "    print(get_replay_info(rpl))\r\n",
    "    print(type(get_replay_info(rpl)))\r\n",
    "    if i == 1:\r\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing inventory in Database\r\n",
    "\r\n",
    "I can store the `Replay_data` objects returned by `get_replay_info` in a document-based database to illustrate how this function could store an inventory or replay information in such a format. Storing this inventory means that other processes could access it to navigate the information built by the ingest process.\r\n",
    "\r\n",
    "In the case of `sc_training`, I use a `config.json` file stored in the working project's data folder to set up a MongoDB local client and, through it, a database. The following code loads this file and defines the loading procedure for when this module is imported. \r\n",
    "\r\n",
    "I will divide this loading process into three steps. First, I locate and load the `config` file. This location process allows users to create a custom `config.json` in a data directory in their projects. That file can be used to customise the name of the database, the port address and number for the MongoDB client, and the location of the replays the user wants to process. \r\n",
    "\r\n",
    "Apart from this option, the code also defines how the module can default to a `config` file stored in the library's data folder if the user fails to provide this file. This default file allows the system to attempt to function based on the assumption that the users are using a Windows computer and have a traditional installation of StarCraft II and MongoDB. Of course, this default set-up would not be expected to work in all cases, but it provides an option and a sample of the `config` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the file is located, I also define a procedure to ensure it contains the necessary information to connect with the MongoDB client and access the appropriate database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\r\n",
    "@dataclass\r\n",
    "class Config_settings:\r\n",
    "    port_address: str\r\n",
    "    port_number: int\r\n",
    "    db_name: str\r\n",
    "    replay_path: str\r\n",
    "\r\n",
    "    def __str__(self):\r\n",
    "        headers = [\"Port Address: \",\"Port Number: \",\r\n",
    "                  \"DB Name: \",\"Replays file: \"]\r\n",
    "        strings = [f'{h:<15}{att:>40}\\n' for h, att\r\n",
    "                   in zip(headers, astuple(self))]\r\n",
    "        return ''.join(strings)\r\n",
    "        \r\n",
    "Config_schema = {\r\n",
    "    \"type\": \"object\",\r\n",
    "    \"properties\":{\r\n",
    "        \"DB_NAME\": {\"type\":\"string\"},\r\n",
    "        \"PORT_ADDRESS\":  {\"type\":\"string\"},\r\n",
    "        \"PORT_NUMBER\": {\"type\":\"number\"},\r\n",
    "        \"REPLAY_PATH\": {\"type\":\"string\"}\r\n",
    "    }\r\n",
    "}\r\n",
    "\r\n",
    "def validate_config_file(file: Path, schema: Dict[str, Any]) -> bool:\r\n",
    "    try:\r\n",
    "        validate(file, schema)\r\n",
    "    except jsonschema.exceptions.ValidationError as err:\r\n",
    "        print(err)\r\n",
    "        print(\"config.json does not conform to the required specifications\")\r\n",
    "        raise err\r\n",
    "    except jsonschema.exceptions.SchemaError as err:\r\n",
    "        print(err)\r\n",
    "        print(\"The Config_schema is invalid\")\r\n",
    "        raise err\r\n",
    "    \r\n",
    "    return True\r\n",
    "\r\n",
    "def open_config_file(config_file: Path) -> dict[str, Any]:\r\n",
    "    try:\r\n",
    "        if not config_file.exists():\r\n",
    "            raise FileNotFoundError\r\n",
    "        \r\n",
    "        validate_config_file(json.load(config_file.open()), Config_schema)\r\n",
    "        \r\n",
    "        with config_file.open('r') as cf:\r\n",
    "            return json.load(cf)\r\n",
    "\r\n",
    "    except FileNotFoundError as err:\r\n",
    "        print('config.json not found')\r\n",
    "        raise err\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of those check and load procedures are contained within the `load_configurations` helper function. The following sample code uses shows the use of this fucntion to set up a test data base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\r\n",
    "def load_configurations() -> Config_settings:\r\n",
    "    \"\"\"Loads the project's\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    config_file = (Path(Path.cwd()/'data/config.json') \r\n",
    "               if Path(Path.cwd()/'data/config.json').exists()\r\n",
    "               else Path(Path(__file__)/'../../../data/config.json'))\r\n",
    "\r\n",
    "    config_dict = open_config_file(config_file)\r\n",
    "    return Config_settings(\r\n",
    "        config_dict['PORT_ADDRESS'],\r\n",
    "        config_dict['PORT_NUMBER'],\r\n",
    "        config_dict['DB_NAME'],\r\n",
    "        config_dict['REPLAY_PATH']\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_settings = load_configurations()\r\n",
    "mongo_client = pymongo.MongoClient(db_settings.port_address, \r\n",
    "                                   db_settings.port_number)\r\n",
    "worcking_bd = mongo_client[db_settings.db_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json content:\n",
      "Port Address:                                 localhost\n",
      "Port Number:                                      27017\n",
      "DB Name:                                   TEST_library\n",
      "Replays file:          .\\test_replays\\TestProfilerBatch\n",
      "\n",
      "Local Mongo DB Client\n",
      "MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)\n",
      "\n",
      "Database: \n",
      "Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'TEST_library')\n"
     ]
    }
   ],
   "source": [
    "print('config.json content:')\r\n",
    "print(db_settings)\r\n",
    "print('Local Mongo DB Client')\r\n",
    "print(mongo_client, end='\\n\\n')\r\n",
    "print('Database: ')\r\n",
    "print(worcking_bd)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the database is set, I can loop through the replays in a file inserting the return values of the functions from the ingest subpackage's different modules into collections within the database. \r\n",
    "\r\n",
    "According to the Ingest and Clustering Sequence Diagram (see Section 1 Intro), I need to define a function that takes a batch of replays and inserts the indexing data into the `replays` collection. The following code shows the use of a loop that would do precisely that. \r\n",
    "\r\n",
    "> Note: in the example, I set up a new database called `sample_db` that I will use in this notebook for illustration purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_db = mongo_client['sample_db']\r\n",
    "collection = sample_db['replays']\r\n",
    "\r\n",
    "replay_batch = sc2reader.load_replays(db_settings.replay_path)\r\n",
    "\r\n",
    "# for rpl in replay_batch:\r\n",
    "#     if not collection.count_documents({'replay_name': rpl.filename}, \r\n",
    "#                                       limit = 1):\r\n",
    "#         # print(f'Adding {Path(rpl.filename).name} to replays collection.')\r\n",
    "#         collection.insert_one(asdict(get_replay_info(rpl)))\r\n",
    "#     else:\r\n",
    "#         print(rpl.filename, \"already exists in the replay_info collection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the loop finishes, the collection has been created in the database. The following snippet shows that this collection is now composed of several documents containing the indexing data for each replay. Additionally, I added a conditional statement within the loop to check if the collection already contains a replay. In that case, the loop will print a warning and avoid inserting repeated documents into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The collection now contains: 153 documents\n"
     ]
    }
   ],
   "source": [
    "print('The collection now contains:', \r\n",
    "      collection.estimated_document_count(), 'documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the `indicators` collection\r\n",
    "\r\n",
    "Similarly, I can loop through every replay in a batch, extracting the performance indicators for each replays' players. Moreover, I can store these indicators as separate documents in a second collection (i.e. rpl_indicators). This two collection approach was defined in Section 1's introduction.\r\n",
    "\r\n",
    "In the following code, I illustrate how such a loop would apply all the functions defined in the ingest subpackage to build the indicators of two players in a sample replay. Each player's indicators are stored in a single flat dictionary, i.e. a dictionary that has no nested data structures as values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_indicators(nested_dict: dict[str, Any]) -> dict[str, float]:\r\n",
    "    output_dict = {}\r\n",
    "    for k, nested in nested_dict.items():\r\n",
    "        for nested_k, v in nested.items():\r\n",
    "            output_dict[f'{k}_{nested_k}'] = v\r\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: test_replays\\Jagannatha LE.SC2Replay\n",
      "Processing player: pid:1 Player 1 - HDEspino (Protoss)\n",
      "Processing player: pid:2 Player 2 - MxChrisxM (Terran)\n"
     ]
    }
   ],
   "source": [
    "indicators = sample_db['indicators']\r\n",
    "\r\n",
    "sample_replay = [sc2reader.load_replay('test_replays\\Jagannatha LE.SC2Replay')]\r\n",
    "\r\n",
    "simple_functions = [get_player_macro_econ_stats,\r\n",
    "                    get_expan_times,\r\n",
    "                    get_expan_counts,\r\n",
    "                    list_player_upgrades,\r\n",
    "                    calc_spe_abil_ratios,\r\n",
    "                    get_prefered_spec_abil,\r\n",
    "                    calc_attack_ratio,\r\n",
    "                    calc_ctrlg_ratio,\r\n",
    "                    count_max_active_groups,\r\n",
    "                    calc_get_ctrl_grp_ratio,\r\n",
    "                    calc_select_ratio]\r\n",
    "\r\n",
    "double_functions = [count_composition,\r\n",
    "                    count_started]\r\n",
    "\r\n",
    "\r\n",
    "indicators_list = []\r\n",
    "for rpl in sample_replay:\r\n",
    "    print(f'Processing: {rpl.filename}')\r\n",
    "    for pid, player in rpl.player.items():\r\n",
    "        print(f'Processing player: pid:{pid} {player}')\r\n",
    "        rpl_indicators = {}\r\n",
    "        \r\n",
    "        for func in simple_functions:\r\n",
    "            rpl_indicators.update(func(rpl, pid))\r\n",
    "\r\n",
    "        for func in double_functions:\r\n",
    "            for flag in [True, False]:\r\n",
    "                rpl_indicators.update(flatten_indicators(func(rpl, pid, flag)))\r\n",
    "                \r\n",
    "        indicators_list.append(rpl_indicators)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "replay_name                   test_replays\\Jagannatha LE.SC2Replay\n",
       "player_username                                          MxChrisxM\n",
       "player_id                                                        2\n",
       "unspent_minerals_avg_whole                              913.392857\n",
       "unspent_minerals_avg_early                              309.852941\n",
       "                                              ...                 \n",
       "late_started_siegetank                                           0\n",
       "late_started_thor                                                4\n",
       "late_started_viking                                              0\n",
       "late_started_warhound                                            0\n",
       "late_started_widowmine                                           0\n",
       "Name: 0, Length: 373, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullArgSpec(args=['rpl', 'pid', 'buildings'], varargs=None, varkw=None, defaults=(False,), kwonlyargs=[], kwonlydefaults=None, annotations={'return': dict[str, dict[str, int]], 'rpl': <class 'sc2reader.resources.Replay'>, 'pid': <class 'int'>, 'buildings': <class 'bool'>})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\r\n",
    "\r\n",
    "inspect.getfullargspec(count_composition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportable functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\r\n",
    "def inventory_replays():\r\n",
    "    pass\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\r\n",
    "def get_replay_indicators():\r\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('sctraining_env': conda)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
