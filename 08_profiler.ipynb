{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp profiler\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\r\n",
    "from nbdev.showdoc import *\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\r\n",
    "import sc2reader\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import re\r\n",
    "import pymongo\r\n",
    "import csv\r\n",
    "\r\n",
    "from typing import *\r\n",
    "\r\n",
    "from sc_training.ingest import *\r\n",
    "\r\n",
    "sc2reader.engine.register_plugin(CtrlGroupTracker())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Player Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\r\n",
    "\r\n",
    "In this section, I use the database built in Section 1.7 to define a `player_profiler` function that will take the data of each player's performances and then it will process it to compile three player profiles for each player, each corresponding to one of the play races of StarCraft 2. The section compiles this function into the `profiler` module.\r\n",
    "\r\n",
    "### Exportable Members\r\n",
    "\r\n",
    "- `build_player_race_profiles`\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the database\r\n",
    "\r\n",
    "Once the ingestion process is done, the next step is to turn the replays data in the database into player profiles. To build these profiles, I need to separate the replays by player and then by race. To accomplish the former, I need to extract a list of **usernames** from the database. \r\n",
    "\r\n",
    "The following code shows how to extract a list of player usernames looping through the `replays` collection created in the ingest process.\r\n",
    "\r\n",
    "> Tip: I will ignore the usernames that follow the pattern 'A.I. number (level)' because they refer to the game's A.I. opponents. Similarly, I ignore the names 'Player 2' and those composed only by repeating the letter 'l' (known as a barcode name). This condition is necessary because players use these two patterns to hide their identity by blending with other players that use the same username. Hence they cannot be used to separate players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HDEspino': 149,\n",
       " 'DaveyC': 2,\n",
       " 'Xnorms': 2,\n",
       " 'Shah': 3,\n",
       " 'Razer': 2,\n",
       " 'gae': 2,\n",
       " 'SenorCat': 2,\n",
       " 'Worawit': 2,\n",
       " 'aria': 2,\n",
       " 'xiiaoyao': 2}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\r\n",
    "# Load database\r\n",
    "working_db = set_up_db()\r\n",
    "\r\n",
    "# Define username patters to ignore\r\n",
    "ai_pat = re.compile(r'^A\\.I\\. [\\d] [(][\\w\\s]*[)]$')\r\n",
    "barcode_pat = re.compile(r'^l+$')\r\n",
    "\r\n",
    "# Iterate through the records in the `replays` collection to get all valid\r\n",
    "# user names.\r\n",
    "players_match_count = dict()\r\n",
    "for rec in working_db['replays'].find():\r\n",
    "    for player in rec['players']:\r\n",
    "        if not (ai_pat.findall(player['username']) \r\n",
    "                or barcode_pat.findall(player['username'])\r\n",
    "                or player['username'] == 'Player 2'):\r\n",
    "            players_match_count.setdefault(player['username'], 0)\r\n",
    "            players_match_count[player['username']] += 1\r\n",
    "            \r\n",
    "# I will ignore players that only have one record in the database.\r\n",
    "{name: count for name , count in players_match_count.items() if count >= 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of this players I will focus only on `HDEspino` given that the player has a substancial number of replays in the test database. \r\n",
    "\r\n",
    "In any case, once I have a list of user names in a database, I can extract all the replays replative to that player with simple queries to the data base. \r\n",
    "\r\n",
    "For example, the following queries extract all replays were `HDEspino` was playing either as player one or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "print(len([rpl for rpl \r\n",
    "           in working_db['replays'].find({'players.0.username':'HDEspino',\r\n",
    "                                          'players.0.race':'Protoss'})]))\r\n",
    "print(len([rpl for rpl \r\n",
    "           in working_db['replays'].find({'players.1.username':'HDEspino',\r\n",
    "                                          'players.1.race':'Protoss'})]))\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the profile\r\n",
    "\r\n",
    "Based on this list, I will build the Protoss profile for this player to illustrate what this process would entail.\r\n",
    "\r\n",
    "First, I will query the system to identify the replays where the user was one of the players and was playing as Protoss. Then, I use that information to build a DataFrame containing all of the indicators for the player's performances in these replays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\r\n",
    "# Query `replays` and build a list of replays the user played as\r\n",
    "# Protoss and Player 1. \r\n",
    "player_1_protoss = [rpl['replay_name'] for rpl \r\n",
    "                   in working_db['replays'].\r\n",
    "                      find({'players.0.username':'HDEspino', \r\n",
    "                            'players.0.race':'Protoss'},\r\n",
    "                            {'replay_name':1, 'players':1})]\r\n",
    "\r\n",
    "# Based on the list query `indicators` to get the performance scores of \r\n",
    "# Player 1 in each replay of the previous list.\r\n",
    "working_repls = {}\r\n",
    "for rpl in player_1_protoss:\r\n",
    "    for cur in working_db['indicators'].find({'replay_name':rpl, \r\n",
    "                                              'player_id': 1}, \r\n",
    "                                             {'_id':0, 'replay_name':0,\r\n",
    "                                              'player_username':0,\r\n",
    "                                              'player_id': 0}):\r\n",
    "        working_repls[rpl] = cur\r\n",
    "        \r\n",
    "len(working_repls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130 entries, 0 to 129\n",
      "Columns: 389 entries, unspent_minerals_avg_whole to late_started_zealot\n",
      "dtypes: float64(97), int64(284), object(8)"
     ]
    }
   ],
   "source": [
    "# \r\n",
    "# Repeat the process above but focused on the replays where the player\r\n",
    "# played as Player 2.\r\n",
    "\r\n",
    "player_2_protoss = [rpl['replay_name'] for rpl \r\n",
    "                   in working_db['replays'].\r\n",
    "                      find({'players.1.username':'HDEspino', \r\n",
    "                            'players.1.race':'Protoss'},\r\n",
    "                            {'replay_name':1, 'players':1})]\r\n",
    "\r\n",
    "for rpl in player_2_protoss:\r\n",
    "    for cur in working_db['indicators'].find({'replay_name':rpl, \r\n",
    "                                              'player_id': 2}, \r\n",
    "                                             {'_id':0, 'replay_name':0,\r\n",
    "                                              'player_username':0,\r\n",
    "                                              'player_id': 0}):\r\n",
    "        working_repls[rpl] = cur\r\n",
    "   \r\n",
    "working_df = (pd.DataFrame(working_repls.values(), \r\n",
    "                           index=working_repls.keys()).reset_index()\r\n",
    "                                                      .drop('index', axis=1))\r\n",
    "working_df.info(memory_usage=False, show_counts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting all replays relative to a player and race, I group them into a DataFrame. In the sample case, the DataFrame has 130 entries and 385 columns. These columns represent the indicators stored by `inventory_replays` into the `indicators` collection.\r\n",
    "\r\n",
    "More importantly, I see that there are three types of data stored in the columns (97 store decimals (type float64), 284 store integers (type int64) and 8 store other value types). In this case, the other value types are categorical values in the form of strings, which store the players' first and second prefered special abilities, as I show in the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = working_df.dtypes[working_df.dtypes == object]\r\n",
    "\r\n",
    "cat_features = working_df[[x for x in categorical_columns.index]]\r\n",
    "\r\n",
    "# I only include 4 of the 8 columns for space.\r\n",
    "pref_abil_df = working_df[['first_whole_pref_sab',\r\n",
    " 'second_whole_pref_sab',\r\n",
    " 'first_mid_pref_sab',\r\n",
    " 'second_mid_pref_sab']]\r\n",
    "\r\n",
    "# print(pref_abil_df.tail(5).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     | first_whole_pref_sab   | second_whole_pref_sab   | first_mid_pref_sab    | second_mid_pref_sab   |\r\n",
    "|----:|:-----------------------|:------------------------|:----------------------|:----------------------|\r\n",
    "| 125 | ChronoBoostEnergyCost  | None                    | None                  | None                  |\r\n",
    "| 126 | ChronoBoostEnergyCost  | UnloadTargetWarpPrism   | ChronoBoostEnergyCost | UnloadTargetWarpPrism |\r\n",
    "| 127 | ForceField             | ChronoBoostEnergyCost   | ForceField            | GuardianShield        |\r\n",
    "| 128 | ChronoBoostEnergyCost  | ForceField              | ChronoBoostEnergyCost | ForceField            |\r\n",
    "| 129 | ChronoBoostEnergyCost  | None                    | None                  | None                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can process this categories using the `value_counts` function to get the most common preffered ability. Next I define `get_top_of_category` to extract the most used attribute in a column.\r\n",
    "\r\n",
    "> Note: once I move into clustering I will need to turn this data into a numerical representation. For example, since this are cardinal categories I could convert the data into a binary matrix (one-hot-matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\r\n",
    "def get_top_of_category(column: pd.Series) -> str:\r\n",
    "\r\n",
    "    return column.value_counts().reset_index().iloc[0]['index']\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ChronoBoostEnergyCost'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_of_category(pref_abil_df.first_whole_pref_sab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_whole_pref_sab     ChronoBoostEnergyCost\n",
       "second_whole_pref_sab           GuardianShield\n",
       "first_early_pref_sab     ChronoBoostEnergyCost\n",
       "second_early_pref_sab                     None\n",
       "first_mid_pref_sab       ChronoBoostEnergyCost\n",
       "second_mid_pref_sab                       None\n",
       "first_late_pref_sab                       None\n",
       "second_late_pref_sab                      None\n",
       "dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_profile = cat_features.apply(get_top_of_category, axis=0)\r\n",
    "cate_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile, I will simply average all other columns to get a single value for the players profile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130 entries, 0 to 129\n",
      "Columns: 381 entries, unspent_minerals_avg_whole to late_started_zealot\n",
      "dtypes: float64(97), int64(284)\n",
      "memory usage: 387.1 KB\n"
     ]
    }
   ],
   "source": [
    "non_cat_columns = working_df.dtypes[working_df.dtypes != object]\r\n",
    "\r\n",
    "non_cat_features = working_df[[x for x in non_cat_columns.index]]\r\n",
    "non_cat_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unspent_minerals_avg_whole    1068.323130\n",
       "unspent_minerals_avg_early     184.596550\n",
       "unspent_minerals_avg_mid       651.947283\n",
       "unspent_minerals_avg_late     2307.746755\n",
       "unspent_vespene_avg_whole      531.042321\n",
       "                                 ...     \n",
       "late_started_stalker             5.123077\n",
       "late_started_tempest             0.584615\n",
       "late_started_voidray             5.069231\n",
       "late_started_warpprism           0.123077\n",
       "late_started_zealot              3.215385\n",
       "Length: 381, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_cate_profile = non_cat_features.mean()\r\n",
    "non_cate_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once these two sets of values are defined, I can join them in a single profile. \r\n",
    "\r\n",
    "> Note: When merging the two sets, I define a 'player_profile' value as an identifier for the profile and a shared column that allows the merge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1 entries, 0 to 0\n",
      "Columns: 390 entries, player_profile to second_late_pref_sab\n",
      "dtypes: float64(381), object(9)\n",
      "memory usage: 3.1+ KB\n"
     ]
    }
   ],
   "source": [
    "profile_name = 'player_profile'\r\n",
    "left = pd.DataFrame(non_cate_profile.to_dict(), index=[0])\r\n",
    "left.insert(0, profile_name, 'HDEspino_protoss')\r\n",
    "right = pd.DataFrame(cate_profile.to_dict(), index=[0])\r\n",
    "right.insert(0, profile_name, 'HDEspino_protoss')\r\n",
    "\r\n",
    "full_profile =  left.merge(right, how='inner', on=profile_name)\r\n",
    "full_profile.info()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\r\n",
    "# print(full_profile.T.head(10).to_markdown())\r\n",
    "# print(full_profile.T.tail(10).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows the resultof the ten first and last indicators in the profile\r\n",
    "and their values. \r\n",
    "\r\n",
    "|              Indicator      | Value              |\r\n",
    "|:----------------------------|:-------------------|\r\n",
    "| player_profile              | HDEspino_protoss   |\r\n",
    "| unspent_minerals_avg_whole  | 1068.32313026423   |\r\n",
    "| unspent_minerals_avg_early  | 184.59654999017428 |\r\n",
    "| unspent_minerals_avg_mid    | 651.9472831545554  |\r\n",
    "| unspent_minerals_avg_late   | 2307.7467547558495 |\r\n",
    "| unspent_vespene_avg_whole   | 531.0423213983343  |\r\n",
    "| unspent_vespene_avg_early   | 109.9563382651504  |\r\n",
    "| unspent_vespene_avg_mid     | 504.7169891278007  |\r\n",
    "| unspent_vespene_avg_late    | 1075.1499164552638 |\r\n",
    "| unspent_resources_avg_whole | 1599.365451662564  |\r\n",
    "| late_started_warpprism      | 0.12307692307692308|\r\n",
    "| late_started_zealot    | 3.2153846153846155    |\r\n",
    "| first_whole_pref_sab   | ChronoBoostEnergyCost |\r\n",
    "| second_whole_pref_sab  | GuardianShield        |\r\n",
    "| first_early_pref_sab   | ChronoBoostEnergyCost |\r\n",
    "| second_early_pref_sab  | None                  |\r\n",
    "| first_mid_pref_sab     | ChronoBoostEnergyCost |\r\n",
    "| second_mid_pref_sab    | None                  |\r\n",
    "| first_late_pref_sab    | None                  |\r\n",
    "| second_late_pref_sab   | None                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportable function\r\n",
    "\r\n",
    "Here, I define `build_player_race_profiles` as a function that converts all replays in a database into a set of player profiles. The function uses four helper functions:\r\n",
    "\r\n",
    "- `get_user_name_list`\r\n",
    "- `get_player_replays`\r\n",
    "- `build_profile`\r\n",
    "- `get_top_of_category` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\r\n",
    "\r\n",
    "def get_user_name_list(active_db: pymongo.database.Database) -> list:\r\n",
    "    # Define username patters to ignore\r\n",
    "    ai_pat = re.compile(r'^A\\.I\\. [\\d] [(][\\w\\s]*[)]$')\r\n",
    "    barcode_pat = re.compile(r'^l+$')\r\n",
    "\r\n",
    "    # Iterate through the records in the `replays` collection to get all valid\r\n",
    "    # user names.\r\n",
    "    players_match_count = dict()\r\n",
    "    for rec in active_db['replays'].find():\r\n",
    "        for player in rec['players']:\r\n",
    "            if not (ai_pat.findall(player['username']) \r\n",
    "                    or barcode_pat.findall(player['username'])\r\n",
    "                    or player['username'] == 'Player 2'):\r\n",
    "                players_match_count.setdefault(player['username'], 0)\r\n",
    "                players_match_count[player['username']] += 1\r\n",
    "\r\n",
    "    return [name\r\n",
    "            for name , count \r\n",
    "            in players_match_count.items() \r\n",
    "            if count >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\r\n",
    "def get_player_replays(active_db: Any, username: str, race: str) -> list:\r\n",
    "    \r\n",
    "    player_1_protoss = [rpl['replay_name'] for rpl \r\n",
    "                        in active_db['replays'].\r\n",
    "                        find({'players.0.username':username, \r\n",
    "                              'players.0.race':race},\r\n",
    "                             {'replay_name':1, 'players':1})]\r\n",
    "\r\n",
    "    # Based on the list query `indicators` to get the performance scores of \r\n",
    "    # Player 1 in each replay of the previous list.\r\n",
    "    working_repls = {}\r\n",
    "    for rpl in player_1_protoss:\r\n",
    "        for cur in active_db['indicators'].find({'replay_name':rpl, \r\n",
    "                                                'player_id': 1}, \r\n",
    "                                                {'_id':0, 'replay_name':0,\r\n",
    "                                                'player_username':0,\r\n",
    "                                                'player_id': 0}):\r\n",
    "            working_repls[rpl] = cur\r\n",
    "\r\n",
    "    player_2_protoss = [rpl['replay_name'] for rpl \r\n",
    "                       in active_db['replays'].\r\n",
    "                       find({'players.1.username':username, \r\n",
    "                             'players.1.race':race},\r\n",
    "                            {'replay_name':1, 'players':1})]\r\n",
    "\r\n",
    "    for rpl in player_2_protoss:\r\n",
    "        for cur in active_db['indicators'].find({'replay_name':rpl, \r\n",
    "                                                'player_id': 2}, \r\n",
    "                                                {'_id':0, 'replay_name':0,\r\n",
    "                                                'player_username':0,\r\n",
    "                                                'player_id': 0}):\r\n",
    "            working_repls[rpl] = cur\r\n",
    "    \r\n",
    "    \r\n",
    "    \r\n",
    "    return working_repls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\r\n",
    "def build_profile(replays_df: pd.DataFrame, \r\n",
    "                  username:str,\r\n",
    "                  race: str) -> pd.DataFrame:\r\n",
    "    \r\n",
    "    \r\n",
    "    categorical_columns = replays_df.dtypes[replays_df.dtypes == object]\r\n",
    "    cat_features = replays_df[[x for x in categorical_columns.index]] \r\n",
    "    cate_profile = cat_features.apply(get_top_of_category, axis=0)\r\n",
    "\r\n",
    "    non_cat_columns = replays_df.dtypes[replays_df.dtypes != object]\r\n",
    "    non_cat_features = replays_df[[x for x in non_cat_columns.index]]\r\n",
    "    non_cate_profile = non_cat_features.mean()\r\n",
    "\r\n",
    "\r\n",
    "    profile_name = 'player_profile'\r\n",
    "    left = pd.DataFrame(non_cate_profile.to_dict(), index=[0])\r\n",
    "    left.insert(0, profile_name, f'{username}_{race}')\r\n",
    "    right = pd.DataFrame(cate_profile.to_dict(), index=[0])\r\n",
    "    right.insert(0, profile_name, f'{username}_{race}')\r\n",
    "\r\n",
    "    return left.merge(right, how='inner', on=profile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\r\n",
    "\r\n",
    "def build_player_race_profiles() -> None:\r\n",
    "    \"\"\"Converts all replays in the project's database, defined in the \r\n",
    "    project's config.json file, into a set of player profiles stored in\r\n",
    "    that same database in the 'Protoss_Profiles', 'Terran_Profiles',\r\n",
    "    and 'Zerg_Profiles' collections.\r\n",
    "    \"\"\"\r\n",
    "    races = ['Protoss', 'Terran', 'Zerg']\r\n",
    "    active_db = set_up_db()\r\n",
    "    print(f'Accessing: {active_db.name}')\r\n",
    "\r\n",
    "    for race in races:\r\n",
    "        active_db[f'{race}_Profiles'].drop()\r\n",
    "    \r\n",
    "\r\n",
    "    user_name_list = get_user_name_list(active_db)\r\n",
    "    print(f'{len(user_name_list)} users found in database')\r\n",
    "\r\n",
    "    print('Generating Player Profiles')\r\n",
    "    counts = {'Protoss':0, 'Zerg': 0, 'Terran':0}\r\n",
    "    for user_name in user_name_list:\r\n",
    "        for race in races:\r\n",
    "            replays = get_player_replays(active_db, user_name, race)\r\n",
    "            \r\n",
    "            if replays:\r\n",
    "                active_replays_df = (pd.DataFrame(replays.values(), \r\n",
    "                                                index=replays.keys())\r\n",
    "                                                .reset_index()\r\n",
    "                                                .drop('index', axis=1))\r\n",
    "\r\n",
    "                act_prf = build_profile(active_replays_df, user_name, race)\r\n",
    "                act_prf_dict_lists = act_prf.to_dict(orient='list')\r\n",
    "                final_act_prf_dict = ({k: v[0] \r\n",
    "                                    for k, v \r\n",
    "                                    in act_prf_dict_lists.items()})\r\n",
    "                \r\n",
    "                active_db[f'{race}_Profiles'].insert_one(final_act_prf_dict)\r\n",
    "                counts[race] += 1\r\n",
    "            \r\n",
    "    print('Created the following profiles')\r\n",
    "    for _race, count in counts.items():\r\n",
    "        print(f'{_race}: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once, I run the function. There is one record in each of the profile databases; the profile of `HDEspino` for each race. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing: TEST_library\n",
      "1 users found in database\n",
      "Generating Player Profiles\n",
      "Created the following profiles\n",
      "Protoss: 1\n",
      "Zerg: 1\n",
      "Terran: 1\n"
     ]
    }
   ],
   "source": [
    "build_player_race_profiles()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(working_db['Protoss_Profiles'].estimated_document_count())\r\n",
    "print(working_db['Terran_Profiles'].estimated_document_count())\r\n",
    "print(working_db['Zerg_Profiles'].estimated_document_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_Comp_model.ipynb.\n",
      "Converted 01_01_ingest_and_clustering.ipynb.\n",
      "Converted 01_summarise_rpl.ipynb.\n",
      "Converted 02_handle_tracker_events.ipynb.\n",
      "Converted 03_macro_econ_parser.ipynb.\n",
      "Converted 04_build_parser.ipynb.\n",
      "Converted 05_handle_command_events.ipynb.\n",
      "Converted 06_selection_parser.ipynb.\n",
      "Converted 07_ingest.ipynb.\n",
      "Converted 08_profiler.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\r\n",
    "from nbdev.export import notebook2script\r\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('sctraining_env': conda)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
