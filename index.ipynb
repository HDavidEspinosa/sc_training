{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SC2 Training Grounds - Technical Specifications Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from sc_training import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document explores the technical back-end design for SC2 Training Grounds. It also functions as the development environment for `sc_training`, a prototype Python library that demonstrates parts of a high-level implementation of this design. \n",
    "\n",
    "> Note: this prototype is primarily meant as a tool for reflective practice. This reflection is part of my PhD research project, \"Encouraging Play Experience Expansion Through Machine-Learning-Based Recommendations: User-Experience Design considerations in the use of Machine-Learning-Based Recommendation System for Video games\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "`sc_training` is a python library developed to document, organise and communicate the design of *SC2 Training Grounds'* computer model. I developed this library for the following purposes:\n",
    "\n",
    "1. To review the technical challenges associated with creating a solution such as *SC2 Training Grounds*.\n",
    "2. To assess the possibilities and limitations of the resources I could use to develop this solution. Therefore, allowing me to design a more realistic and grounded user experience for the application. \n",
    "3. To provide a proof-of-concept that tests the technical feasibility of the project.\n",
    "\n",
    "In this case, I used literate and iterative programming to develop the library while providing a narrative explanation and documentation of this process (Knuth, 1984; Ramsey, 1994; Literate Programming, 2014; Kery et al., 2018). This methodology allows rapid testing and exploration of ideas while integrating them into a functioning program (Howard, 2019). Hence, the library is simultaneously the program's documentation and the program itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the Library's Files and Documentation\n",
    "\n",
    "> Note: a pdf version of this document is attached as Appendix C of my PhD project. This format is included for convenience. However, I remind the reader that, in this format, the library loses part of its original functions as an interactive artefact. Readers can download all the files described below from the following [GitHub repository](https://github.com/HDavidEspinosa/sc_training).\n",
    "\n",
    "To facilitate the use of literate programming, I developed this library using I used [nbdev](https://nbdev.fast.ai/). The use of this tool means that this library is rendered in various ways to accommodate different interests. \n",
    "\n",
    "- First, since nbdev uses _interactive notebooks_ (see [Jupyter notebooks](https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/)) as a development environment, the library was developed and is originally contained in this format. These interactive documents intertwine textual elements that describe the ideas that support its components and the source code that defines its functions (see [Jupyter/IPython Quick Start Guide](https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/) for a guide on how to set up the Jupyter and IPython libraries to use these documents). \n",
    "- Second, the library is also exported as a traditional _python library_. Readers can find a functioning version of all the library's modules in the [repository's `sc_training` folder](https://github.com/HDavidEspinosa/sc_training/tree/master/sc_training), which they can use to replicate and verify any examples and experiments explored in this deliverable. \n",
    "- Third, these notebooks produce a _website_ that serves as the library's [Interactive Documentation](https://hdavidespinosa.github.io/sc_training/). This documentation omits many technical details focusing on the descriptions of the development process and the library's structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Before going into the document itself, it is important to clarify some aspects regarding their composition. \n",
    "\n",
    "Because of the nature of the documents, each notebook is exported as a module of the `sc_training` library. \n",
    "\n",
    "Meanwhile, since each notebook works as a separate module, I have to include some setup elements at the beginning of each document. Since this process is almost identical in most cases, I will cover it here so that I can hide it in the module's documentation.\n",
    "\n",
    "> Note: Remember that any elements I hide in these documents can still be reviewed and verified in the library's development notebooks and the library's exported source code.\n",
    "\n",
    "The development of all modules starts with two elements: importing the module's dependencies and loading the development tests and sample data.\n",
    "\n",
    "Importing the module's dependencies means invoking several libraries used by each module. The following is an example of these imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This are some of the common libraries for this library's\n",
    "# development.\n",
    "\n",
    "# These are some of the libraries of Python's standard library \n",
    "# I use to support different functionalities. \n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from dataclasses import dataclass, astuple, field\n",
    "from datetime import datetime\n",
    "from typing import *\n",
    "\n",
    "# I use the following libries to load and manage data files. \n",
    "import csv\n",
    "import json\n",
    "\n",
    "# Pymongo allows me to interact with a local MongoDB client to \n",
    "# store and manage my document-based database.\n",
    "import pymongo\n",
    "\n",
    "# The following libraries offer various utilities for efficient\n",
    "# data and numeric manipulation, and for data visualisation.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn # Depending on the module I use different modules of\n",
    "               # scikit-learn library.\n",
    "\n",
    "\n",
    "# sc2reader facilitates data extraction from replay files\n",
    "import sc2reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, to develop each module, I need to load some StarCraft II replay files (marked with the .SC2Replay extension). The game generates these files to store all relevant configuration and game-play information necessary to rebuild and reproduce a match. \n",
    "\n",
    "The replays used to test and develop this project are extracted from publicly available datasets. In no case do I access any personal or private information of the users or players. The following code illustrates how they are loaded using `sc2reader` and collected into variables that store `sc2reader.resources.Replay` objects for later processing. I store this data in the repository's `test_replays` folder.\n",
    "\n",
    "> Tip:  One can load one replay at a time using the `sc2replays.load_replay(<str_file_path>)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sc2reader.resources.Replay at 0x1af38d6d610>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code sets up the notebook's sample replay.\n",
    "rps_path = Path(Path.cwd()/'test_replays') \\\n",
    "           if Path('test_replays').exists() \\\n",
    "           else Path('../test_replays')\n",
    "game_path = str(rps_path/'Jagannatha LE.SC2Replay')\n",
    "single_replay = sc2reader.load_replay(game_path)\n",
    "single_replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip: Alternatively, one can use the sc2replays.load_replays(<str_dir_path>) method, which returns a generator of replay objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object SC2Factory.load_all at 0x000001AF3BA9BB30>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replays = sc2reader.load_replays(str(rps_path))\n",
    "replays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond these two initial setup elements, some modules also load data files that store helpful information to organise and configure the modules and their functions. These data files are stored in the library's data folder. The code below illustrates how I load some of these files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(Path.cwd()/'data') \\\n",
    "            if Path('data').exists() \\\n",
    "            else Path('../../data')\n",
    "\n",
    "with open(data_path/'unit_names.csv') as f:\n",
    "    file_reader = csv.reader(f)\n",
    "    unit_names = next(file_reader)\n",
    "    \n",
    "with open(data_path/'changes_names.csv') as f:\n",
    "    file_reader = csv.reader(f)\n",
    "    change_names = next(file_reader)\n",
    "    \n",
    "with open(data_path/'army_list.json') as f:\n",
    "    race_armies = json.load(f)\n",
    "\n",
    "with open(data_path/'buildings_list.json') as f:\n",
    "    race_buildings = json.load(f)\n",
    "\n",
    "with open(data_path/'upgrades.json') as f:\n",
    "    race_upgrades = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportable functions\n",
    "\n",
    "In each module, I include a section where I compile all the exportable functions that respond to each module's challenges and requirements. Once exported, other modules can call these functions by importing the module that exported them in the first place.\n",
    "\n",
    "For example, in the following code, I demonstrate how to call the `get_replay_info` function from the `summarise_rpl` module (see <<3 - Summarising Replays>>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path:                   c:\\Users\\david\\Documents\\phdcode\\sc_training\\test_replays\\Jagannatha LE.SC2Replay \n",
      "File name:                   Jagannatha LE.SC2Replay \n",
      "Date (datetime.datetime):    2021-02-24 02:53:06 \n",
      "Duration (seconds):          590 \n",
      "Game type:                   1v1 \n",
      "Game release:                5.0.6.83830 \n",
      "Map:                         Jagannatha LE \n",
      "Game category:               Ladder \n",
      "winner:                      2 \n",
      "players:                     [(1, 'HDEspino', 'Protoss', 'Loss'), (2, 'MxChrisxM', 'Terran', 'Win')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sc_training.ingest.summarise_rpl import *\n",
    "\n",
    "#Note that get_replay_info is defined in the summarise_rpl module.\n",
    "replay_data = get_replay_info(single_replay)\n",
    "print(replay_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example would be the use of the ingest's sub-package `inventory_replays` function to gather to collect the data from a replay batch into a database. This database is setup using a `config.json` file which ***MUST BE CREATED AND STORED IN THE PROJECT'S DATA FOLDER*** (see `load_configurations` and `set_up_db` in <<9 - The main ingest module>>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inventorying replays at: test_replays\\TestProfilerBatch in database TEST_library\n",
      "Load complete.\n",
      "153 files processed\n",
      "0 files loaded\n",
      "4 files ignored\n",
      "149 files alredy existed\n"
     ]
    }
   ],
   "source": [
    "from sc_training.ingest import *\n",
    "\n",
    "inventory_replays()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this function runs correctly and a batch of replays is processed and its data is stored in the database specified in the `config.json` file, the user can call the `build_player_race_profiles` to extract the race profiles. \n",
    "\n",
    "> Note: that this function only creates a race profile if the player has at least five replays played with that race in the processed batch. In the sample batch only one player fulfills this requirement, that is why only one profile is created per race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing: TEST_library\n",
      "1 users found in database\n",
      "Generating Player Profiles\n",
      "Created the following profiles\n",
      "Protoss: 1\n",
      "Zerg: 1\n",
      "Terran: 1\n"
     ]
    }
   ],
   "source": [
    "from sc_training import *\n",
    "\n",
    "build_player_race_profiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Howard, J. (2019) nbdev: use Jupyter Notebooks for everything fast.ai, fast.ai. Available at: https://www.fast.ai/2019/12/02/nbdev/ (Accessed: 8 July 2021).\n",
    "- Kery, M. B. et al. (2018) 'The Story in the Notebook', in Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. New York, NY, USA: ACM, pp. 1-11. doi: 10.1145/3173574.3173748.\n",
    "- Knuth, D. E. (1984) 'Literate Programming', The Computer Journal, 27(2), pp. 97-111. doi: 10.1093/comjnl/27.2.97.\n",
    "- Literate Programming (2014) WikiWiki. Available at: https://wiki.c2.com/?LiterateProgramming (Accessed: 6 July 2021).\n",
    "- Ramsey, N. (1994) 'Literate programming simplified', IEEE Software, 11(5), pp. 97-105. doi: 10.1109/52.311070."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_Comp_model.ipynb.\n",
      "Converted 01_01_ingest_and_clustering.ipynb.\n",
      "Converted 01_summarise_rpl.ipynb.\n",
      "Converted 02_handle_tracker_events.ipynb.\n",
      "Converted 03_macro_econ_parser.ipynb.\n",
      "Converted 04_build_parser.ipynb.\n",
      "Converted 05_handle_command_events.ipynb.\n",
      "Converted 06_selection_parser.ipynb.\n",
      "Converted 07_ingest.ipynb.\n",
      "Converted 08_profiler.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('sctraining_env': conda)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
