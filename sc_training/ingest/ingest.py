# AUTOGENERATED! DO NOT EDIT! File to edit: 07_ingest.ipynb (unless otherwise specified).

__all__ = ['load_configurations', 'set_up_db', 'inventory_replays']

# Internal Cell

import re
import pymongo
import json
import sc2reader
import errno
import jsonschema
import os

import pandas as pd
import numpy as np

from typing import *
from pathlib import Path
from pprint import pprint
from jsonschema import validate
from dataclasses import dataclass, astuple, asdict, field

from . import *

sc2reader.engine.register_plugin(CtrlGroupTracker())

# Internal Cell
@dataclass
class Config_settings:
    port_address: str
    port_number: int
    db_name: str
    replay_path: str

    def __str__(self):
        headers = ["Port Address: ","Port Number: ",
                  "DB Name: ","Replays file: "]
        strings = [f'{h:<15}{att:>40}\n' for h, att
                   in zip(headers, astuple(self))]
        return ''.join(strings)

Config_schema = {
    "type": "object",
    "properties":{
        "DB_NAME": {"type":"string"},
        "PORT_ADDRESS":  {"type":"string"},
        "PORT_NUMBER": {"type":"number"},
        "REPLAY_PATH": {"type":"string"}
    }
}

def validate_config_file(file: Path, schema: Dict[str, Any]) -> bool:
    try:
        validate(file, schema)
    except jsonschema.exceptions.ValidationError as err:
        print(err)
        print("config.json does not conform to the required specifications")
        raise err
    except jsonschema.exceptions.SchemaError as err:
        print(err)
        print("The Config_schema is invalid")
        raise err

    return True

def open_config_file(config_file: Path) -> dict[str, Any]:
    try:
        if not config_file.exists():
            raise FileNotFoundError

        validate_config_file(json.load(config_file.open()), Config_schema)

        with config_file.open('r') as cf:
            return json.load(cf)

    except FileNotFoundError as err:
        print('config.json not found')
        raise err


# Cell
def load_configurations() -> Config_settings:
    """Loads the project's
    """

    config_file = (Path(Path.cwd()/'data/config.json')
               if Path(Path.cwd()/'data/config.json').exists()
               else Path(Path(__file__)/'../../../data/config.json'))

    config_dict = open_config_file(config_file)
    return Config_settings(
        config_dict['PORT_ADDRESS'],
        config_dict['PORT_NUMBER'],
        config_dict['DB_NAME'],
        config_dict['REPLAY_PATH']
    )

# Internal Cell
def flatten_indicators(nested_value: dict) -> dict[str, float]:

    if isinstance(list(nested_value.values())[0], dict):
        output_dict = {}
        for k, nested in nested_value.items():
            for nested_k, v in nested.items():
                output_dict[f'{k}_{nested_k}'] = v
        return output_dict
    elif isinstance(list(nested_value.values())[0], tuple):
        output_dict = {}
        order = ['first', 'second']
        for k, nested in nested_value.items():
            for ord, v in zip(order, nested):
                output_dict[f'{ord}_{k}'] = str(v)
        return output_dict


# Cell
def set_up_db():
    """Loads the database specified in the project's config.json file.
    """
    db_settings = load_configurations()
    mongo_client = pymongo.MongoClient(db_settings.port_address,
                                    db_settings.port_number)
    worcking_bd = mongo_client[db_settings.db_name]

    return worcking_bd

# Internal Cell
def verify_replays_path(rpl_path: Any) -> Path:

    if isinstance(rpl_path, str):
        path = Path(rpl_path)
    elif not isinstance(rpl_path, Path):
        string = 'replay_path must be of type str or Path, not '
        raise TypeError((string + str(type(replay_batch))))
    else:
        path = rpl_path

    if not path.exists():
        raise ValueError(f'{path} is not valid location')

    return path

# Internal Cell
def build_indicators(rpl: sc2reader.resources.Replay,
                    working_db: pymongo.database.Database) -> None:

    """Runs through the indicator extraction loop and stores the results
    in the indicators collections.
    """
    simple_functions = [get_player_macro_econ_stats,
                        get_expan_times,
                        get_expan_counts,
                        calc_attack_ratio,
                        calc_ctrlg_ratio,
                        count_max_active_groups,
                        calc_get_ctrl_grp_ratio,
                        calc_select_ratio,
                        list_player_upgrades,
                        calc_spe_abil_ratios
                        ]

    double_functions = [count_composition,
                        count_started]
    indi_collect = worcking_bd['indicators']
    for pid, player in rpl.player.items():
        rpl_indicators = {}
        for func in simple_functions:
            rpl_indicators.update(func(rpl, pid))

        v = get_prefered_spec_abil(rpl, pid)
        rpl_indicators.update(flatten_indicators(v))

        for func in double_functions:
            for flag in [True, False]:
                rpl_indicators.update(flatten_indicators(func(rpl, pid, flag)))

        rpl_ind = ({k: v
                    if (not (isinstance(v, np.int64)
                        or isinstance(v, np.float64)))
                    else float(v) for k, v in rpl_indicators.items()})

        indi_collect.insert_one(rpl_ind)

# Cell
def inventory_replays(replay_batch: Any) -> None:
    """This function builds four collections within the database
    specified in the config.json file.

    - `replays`
        Stores the metadata of the replays, can be used for indexing and
        for finding the other replays.
    - `inicators_Protoss`, `indicator_Terran`, `indicators_Zerg`
        Store the indicators for each performance of every player,
        separated by the race they play with in every match.
    """
    working_db = set_up_db()
    rpls_collect = working_db['replays']
    path = verify_replays_path(replay_batch)

    replays = sc2reader.load_replays(str(path))

    load_count = 0
    process_count = 0
    previous = 0
    ignored = 0
    for rpl in replays:
        process_count += 1
        if (not (rpl.type == "1v1")):
            ignored += 1
            # print(f'{rpl.filename}is not 1v1')
            continue
        if not rpls_collect.count_documents({'replay_name': rpl.filename},
                                            limit = 1):
            # print(f'Processing {rpl.filename}')
            rpls_collect.insert_one(asdict(get_replay_info(rpl)))
            build_indicators(rpl, worcking_bd)
            load_count += 1
        else:
            previous += 1
            # print(rpl.filename, "already exists in the replay_info rpls_collect.")

    print(f'Load complete.')
    print(f'{process_count} files processed')
    print(f'{load_count} files loaded')
    print(f'{ignored} files ignored')
    print(f'{previous} files alredy existed')
