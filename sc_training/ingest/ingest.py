# AUTOGENERATED! DO NOT EDIT! File to edit: 07_ingest.ipynb (unless otherwise specified).

__all__ = ['Config_settings', 'load_configurations', 'set_up_db', 'inventory_replays']

# Internal Cell

import re
import pymongo
import json
import sc2reader
import errno
import jsonschema
import os

import pandas as pd
import numpy as np

from typing import *
from pathlib import Path
from pprint import pprint
from jsonschema import validate
from dataclasses import dataclass, astuple, asdict, field

from sc2reader.engine.plugins import APMTracker

from . import *
sc2reader.engine.register_plugin(APMTracker())
sc2reader.engine.register_plugin(CtrlGroupTracker())

# Internal Cell

# This section defines the helper functions I use in the
# config file loading and checking procedure
# To check that the config file contains all necessary information for
# the solution's proper working I use the following jsonschema
Config_schema = {
    "type": "object",
    "properties":{
        "DB_NAME": {"type":"string"},
        "PORT_ADDRESS":  {"type":"string"},
        "PORT_NUMBER": {"type":"number"},
        "REPLAY_PATH": {"type":"string"}
    }
}


def validate_config_file(file: Path, schema: Dict[str, Any]) -> bool:
    """This helper function uses the json schema defined above to
    make sure that the config file includes all the information
    necessary for the solution's proper work"""
    try:
        validate(file, schema)
    except jsonschema.exceptions.ValidationError as err:
        print(err)
        print("config.json does not conform to the required specifications")
        raise err
    except jsonschema.exceptions.SchemaError as err:
        print(err)
        print("The Config_schema is invalid")
        raise err

    return True

# Using the validate_config_file function I can check that the config
# file exists and has the proper information for sc_training to work.

def open_config_file(config_file: Path) -> dict[str, Any]:
    """This helper function verifies the existence of the config file
    and that it has the proper data. If so it imports the data into a
    dict that can be used to access such data in the program"""
    try:
        if not config_file.exists():
            raise FileNotFoundError

        validate_config_file(json.load(config_file.open()), Config_schema)

        with config_file.open('r') as cf:
            return json.load(cf)

    except FileNotFoundError as err:
        print('config.json not found')
        raise err


# Cell
@dataclass
class Config_settings:
    """This type of object stores the data extracted from the config file.

    *Attributes*
        - port_address: str
            Address of the MongoDB Client that the program will connect to.
        - port_number: int
            Port number of the client located in the address above
        - db_name: str
            Name of the project's data base
        - replay_path: str
            Path to the replays that must be analysed and stored in the
            database
"""
    port_address: str
    port_number: int
    db_name: str
    replay_path: str

    def __str__(self):
        headers = ["Port Address: ","Port Number: ",
                  "DB Name: ","Replays file: "]
        strings = [f'{h:<15}{att:>40}\n' for h, att
                   in zip(headers, astuple(self))]
        return ''.join(strings)


# Cell
def load_configurations() -> Config_settings:
    """Loads the project's configuration information.

    This function locates, verifies and extracts the project's configuration
    data. This data tells sc_training where to find the replays it needs to
    inventory and process, how to connect to the MongoDB client it will use
    to store this data in a database, and the name of the database it
    should use.

    *Args*
        - None

    *Returns*
        - Config_settings

    *Errors*
        - FileNotFound
            If there is no valid config file
        - jsonschema.exceptions.ValidationError
            If the config file does not contain the necessary data or does
            not conform to the proper schema necessary to work.
    """

    config_file = (Path(Path.cwd()/'data/config.json')
               if Path(Path.cwd()/'data/config.json').exists()
               else Path(Path(__file__)/'../../../data/config.json'))

    config_dict = open_config_file(config_file)
    return Config_settings(
        config_dict['PORT_ADDRESS'],
        config_dict['PORT_NUMBER'],
        config_dict['DB_NAME'],
        config_dict['REPLAY_PATH']
    )

# Internal Cell
# The following helper function helps eliminate multiple levels of
# nesting in a dictionary
def flatten_indicators(nested_value: dict) -> dict[str, float]:
    if isinstance(list(nested_value.values())[0], dict):
        output_dict = {}
        for k, nested in nested_value.items():
            for nested_k, v in nested.items():
                output_dict[f'{k}_{nested_k}'] = v
        return output_dict
    elif isinstance(list(nested_value.values())[0], tuple):
        output_dict = {}
        order = ['first', 'second']
        for k, nested in nested_value.items():
            for ord, v in zip(order, nested):
                output_dict[f'{ord}_{k}'] = str(v)
        return output_dict


# Cell
def set_up_db() -> pymongo.database.Database:
    """Loads the database specified in the project's config.json file.

    *Returns*
        - pymongo.database.Database
            Python object that allows the user to interact with the
            database specified in the project's config file.
    """
    db_settings = load_configurations()
    mongo_client = pymongo.MongoClient(db_settings.port_address,
                                    db_settings.port_number)
    worcking_bd = mongo_client[db_settings.db_name]

    return worcking_bd

# Internal Cell
# Helper function that verifies the path of the where the replays should
# be located according to the config file.
def verify_replays_path(rpl_path: Any) -> Path:

    if isinstance(rpl_path, str):
        path = Path(rpl_path)
    elif not isinstance(rpl_path, Path):
        string = 'replay_path must be of type str or Path, not '
        raise TypeError((string + str(type(replay_batch))))
    else:
        path = rpl_path

    if not path.exists():
        raise ValueError(f'{path} is not valid location')

    return path

# Internal Cell
# Helper function that extracts the indicators for each matc's players and
# stores it in the indicators collection.
def build_indicators(rpl: sc2reader.resources.Replay,
                    working_db: pymongo.database.Database) -> None:

    """Runs through the indicator extraction loop and stores the results
    in the indicators collections.
    """
    simple_functions = [get_player_macro_econ_stats,
                        get_expan_times,
                        get_expan_counts,
                        calc_attack_ratio,
                        calc_ctrlg_ratio,
                        count_max_active_groups,
                        calc_get_ctrl_grp_ratio,
                        calc_select_ratio,
                        list_player_upgrades,
                        calc_spe_abil_ratios,
                        calc_apms
                        ]

    double_functions = [count_composition,
                        count_started]
    indi_collect = working_db['indicators']
    for pid in rpl.player.keys():
        rpl_indicators = {}
        for func in simple_functions:
            rpl_indicators.update(func(rpl, pid))

        v = get_prefered_spec_abil(rpl, pid)
        rpl_indicators.update(flatten_indicators(v))

        for func in double_functions:
            for flag in [True, False]:
                rpl_indicators.update(flatten_indicators(func(rpl, pid, flag)))

        rpl_ind = ({k: v
                    if (not (isinstance(v, np.int64)
                        or isinstance(v, np.float64)))
                    else float(v) for k, v in rpl_indicators.items()})

        indi_collect.insert_one(rpl_ind)

# Cell
def inventory_replays() -> None:
    """This function builds two collections within the database
    specified in the config.json file.

    The replay information will be stored in the database specified in
    cwd/data/config.json in the following collections:
    - `replays`
        Stores the metadata of the replays, can be used for indexing and
        for finding the other replays.
    - `inicators`
        Store the indicators for each performance of every player.

    *Args:*
        - replay_batch
            Directory address where the replays to process are located.

    *Return:*
        -None

    """
    project_config = load_configurations()
    working_db = set_up_db()
    rpls_collect = working_db['replays']
    path = verify_replays_path(project_config.replay_path)

    replays = sc2reader.load_replays(str(path))

    load_count = 0
    process_count = 0
    previous = 0
    ignored = 0

    print(f'Inventorying replays at: {path} in database {working_db.name}')

    for rpl in replays:
        process_count += 1
        if (not (rpl.type == "1v1")):
            ignored += 1
            # print(f'{rpl.filename}is not 1v1')
            continue
        if not rpls_collect.count_documents({'replay_name': rpl.filename},
                                            limit = 1):
            # print(f'Processing {rpl.filename}')
            rpls_collect.insert_one(asdict(get_replay_info(rpl)))
            build_indicators(rpl, working_db)
            load_count += 1
        else:
            previous += 1
            # print(rpl.filename, "already exists in the replay_info rpls_collect.")

    print(f'Load complete.')
    print(f'{process_count} files processed')
    print(f'{load_count} files loaded')
    print(f'{ignored} files ignored')
    print(f'{previous} files alredy existed')
